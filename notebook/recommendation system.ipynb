{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167ecae5",
   "metadata": {},
   "source": [
    "# Movie Recommendations Using Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93b975",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "#### Overall Objective of the project: \n",
    "\n",
    "- Predict users' movie preferences and suggest a list of movies that are likely to be watched. In other words, give personalized suggestions on movies to watch for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef3421",
   "metadata": {},
   "source": [
    "\n",
    "### Recommendation systems :\n",
    "\n",
    "\n",
    "#### What is a Recommendation system?\n",
    "\n",
    "- A recommendation system suggests a product or service to customers who are likely to consume or purchase it.\n",
    "\n",
    "- Recommendation systems are utilized in e-commerce to predict the preference a user might give to an item.\n",
    "  - Netflix : Which movie to watch.\n",
    "  - Amazon : Which products are similar to the one purchased.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbd6ce",
   "metadata": {},
   "source": [
    "- Other examples of recommendation systems and applications:\n",
    "\n",
    "  - Spotify recommends music and playlist\n",
    "  - Facebook recommends friends\n",
    "  - LinkedIn recommends jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a299ef7",
   "metadata": {},
   "source": [
    "- The Netflix prize (competition 2009)\n",
    "\n",
    "    -  Competition for the best collaborative filtering algorithm to predict user ratings for films.\n",
    "\n",
    "   -  Data: Around 100M ratings from 500K  users on 18K movies.\n",
    "\n",
    "   -  Winning team used: A Regularized matrix factorization approach. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6b276",
   "metadata": {},
   "source": [
    "#### Recomendation system\n",
    "\n",
    "Data required for Recommendation system:\n",
    "\n",
    "- User ratings data\n",
    "- Variables related to items or users (movies genre, duration of the movie... etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22020edb",
   "metadata": {},
   "source": [
    "#### Recomendation systems : Collaborative filtering\n",
    "\n",
    "- **Main idea**: Recommending items to users based on the preference of similar users.\n",
    "   - Based on data, we asumme that: A user who has agreed in past tends to also agree in future.\n",
    "   \n",
    "   \n",
    "- We only have ratings of user for items.\n",
    "     - Users are consumers.\n",
    "     - Items are the products or services offered.\n",
    "\n",
    "\n",
    "- **Approach** : Build an \"utility\" matrix that captures interactions between users and items.\n",
    "   - each row is a user\n",
    "   - each column and item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0d061",
   "metadata": {},
   "source": [
    "#### Collaborative filtering : Challenges\n",
    "\n",
    "\n",
    "- Sparsity of utility matrix:\n",
    "   - Usually users only interact with a few items.\n",
    "      - Netflix users rate only a few songs.\n",
    "   \n",
    "- Objective?\n",
    " - Given a utility matrix of $N$ users and $M$ items, fill the the missing entries to complete the utility matrix. \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2faea",
   "metadata": {},
   "source": [
    "#### Problem formulation\n",
    "\n",
    "- An Unsupervised Learning approach\n",
    "   - Only uses the user-item utility matrix.\n",
    "\n",
    "- Goal : learn latent features related to users and items.\n",
    "   - **Matrix factorization algorithm** on the utility matrix to learn latent features related to typical users and typical items.\n",
    "   - Use reconstructions to fill in missing entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f8106",
   "metadata": {},
   "source": [
    "#### Problem formulation - Matrix Factorization\n",
    "\n",
    "\n",
    "$$\\hat{Y} = Z W$$\n",
    "$$Y \\approx Z W$$\n",
    "\n",
    "- $Z$ - Transformed data. Users to latent features of items\n",
    "- $W$ - Weights.    Items to latent features of users.\n",
    "\n",
    "Adapted loss function (MSE) because of sparcity of data.\n",
    "\n",
    "\n",
    "$$\\sum_{(i, j) \\in R}  (W_{j}^T  Z_{i} - Y_{i,j})^2$$\n",
    "\n",
    "- Where $R$ is the only available ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e938b",
   "metadata": {},
   "source": [
    "#### Collaborative filtering\n",
    "\n",
    "- Advantage\n",
    "  - It works well when the data is small.\n",
    "  - Little Domain Knowledge\n",
    "\n",
    "- Disadvantage\n",
    "  - Cold Start Problem. Cannot draw inference when new items appear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9badf49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramir\\.conda\\envs\\563\\lib\\site-packages\\ipykernel\\parentpoller.py:109: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  warnings.warn(\"\"\"Parent poll failed.  If the frontend dies,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5bbca1",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "- For this analysis the [MovieLens 100K Dataset](https://www.kaggle.com/datasets/prajitdatta/movielens-100k-dataset) is utilized.\n",
    "\n",
    "- Were collected by the GroupLens Research Project which is a research group in the Department of Computer Science and Engineering at the University of Minnesota\n",
    "\n",
    "This data set consists of:\n",
    "\n",
    "- 100,000 ratings (1-5) from 943 users on 1682 movies.\n",
    "- Each user has rated at least 20 movies.\n",
    "\n",
    "The data was collected during a seven-month period from September 19th, 1997 through April 22nd, 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "cols = [\"user_id\", \"movie_id\", \"rating\", \"timestamp\"]\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(\"data\", \"ml-100k\", \"u.data\"),\n",
    "    sep=\"\\t\",\n",
    "    names=cols,\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "\n",
    "ratings\n",
    "ratings = ratings.drop(columns=[\"timestamp\"])\n",
    "ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies data\n",
    "\n",
    "cols = [\n",
    "    \"movie_id\",\n",
    "    \"movie_title\",\n",
    "    \"release_date\",\n",
    "    \"video_release_date\",\n",
    "    \"IMDb_URL\",\n",
    "    \"unknown\",\n",
    "    \"Action\",\n",
    "    \"Adventure\",\n",
    "    \"Animation\",\n",
    "    \"Children\",\n",
    "    \"Comedy\",\n",
    "    \"Crime\",\n",
    "    \"Documentary\",\n",
    "    \"Drama\",\n",
    "    \"Fantasy\",\n",
    "    \"Film-Noir\",\n",
    "    \"Horror\",\n",
    "    \"Musical\",\n",
    "    \"Mystery\",\n",
    "    \"Romance\",\n",
    "    \"Sci-Fi\",\n",
    "    \"Thriller\",\n",
    "    \"War\",\n",
    "    \"Western\",\n",
    "]\n",
    "\n",
    "movies_data = pd.read_csv(\n",
    "    os.path.join(\"data\", \"ml-100k\", \"u.item\"),\n",
    "    sep=\"|\",\n",
    "    names=cols,\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "movies_data.head()\n",
    "\n",
    "movie_titles = movies_data[['movie_id', 'movie_title']]\n",
    "movie_titles.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017409b0-8b5b-41d6-8ba2-36654670b1d0",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7743e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of the data\n",
    "\n",
    "user_key = \"user_id\"\n",
    "item_key = \"movie_id\"\n",
    "\n",
    "N = len(np.unique(ratings[user_key]))\n",
    "M = len(np.unique(ratings[item_key]))\n",
    "print(\"Number of users  : %d\" % N)\n",
    "print(\"Number of movies : %d\" % M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average number of ratings per user : %.0f\" % (len(ratings) / N))\n",
    "print(\"Average number of ratings per movie: %.0f\" % (len(ratings) / M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_full = pd.merge(ratings, movie_titles, right_on='movie_id', left_on='movie_id')\n",
    "movies_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a0870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_agg = movies_full[['movie_title','rating']].groupby(by='movie_title').agg(['count','mean'])['rating'].reset_index()\n",
    "\n",
    "# If at least 20 rankings\n",
    "\n",
    "top_rankings = movies_agg[movies_agg['count'] >=20].sort_values('mean', ascending=False).iloc[:5]\n",
    "top_rankings['mean'] = top_rankings['mean'].round(decimals = 2)\n",
    "top_rankings\n",
    "\n",
    "# Highest ranked movies by all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_agg = movies_full[['movie_title','rating']].groupby(by='movie_title').agg(['count','mean'])['rating'].reset_index()\n",
    "\n",
    "# If at least 20 rankings\n",
    "\n",
    "# Most ranked movies\n",
    "\n",
    "movies_agg[movies_agg['count'] >=20].sort_values('count', ascending=False).iloc[:5][['movie_title','count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01509ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rankings = movies_agg[movies_agg['count'] >=20].sort_values('mean', ascending=True).iloc[:5]\n",
    "low_rankings['mean'] = low_rankings['mean'].round(decimals = 2)\n",
    "low_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_agg[movies_agg['count'] >=20].sort_values('count', ascending=True).iloc[:5][['movie_title','count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da38118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp = movies_full[['movie_id','rating']].groupby(by='movie_id').agg(['count','mean'])['rating'].reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(df_grp['count'], bins=30)\n",
    "plt.title('Distribution of the number of ratings given per movie', fontsize=18)\n",
    "plt.xlabel('Number of times the movie was rated', fontsize=15)\n",
    "plt.ylabel('Number of films', fontsize=15)\n",
    "plt.savefig(\"hist_dist_count_ratings.png\",dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21572d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.kdeplot(data = df_grp, x = 'mean', bw_method=0.5)\n",
    "plt.title('Distribution of Mean movie rating', fontsize=13)\n",
    "plt.xlabel('Mean movie rating', fontsize=11)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df_grp, x='mean', y='count')\n",
    "plt.title('Scatter plot of movie rating', fontsize=13)\n",
    "plt.xlabel('Mean movie rating', fontsize=11)\n",
    "plt.ylabel('Count of movie ratings', fontsize=11)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = list(movies_data.columns[6:])\n",
    "genre_counts = movies_data[genres].sum(axis=0)\n",
    "genre_counts= pd.DataFrame(genre_counts,  columns=['counts'])\n",
    "genre_counts_sorted = genre_counts.sort_values(by = 'counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd32bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Most Popular Genres', fontsize=18)\n",
    "plt.ylabel('Genres', fontsize=15)\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.barplot(x='counts',y =genre_counts.index, data=genre_counts_sorted) \n",
    "plt.xlabel('Count', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598ef96",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11116db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings.copy()\n",
    "y = ratings[\"user_id\"]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "## Mapper to train Map ratings\n",
    "\n",
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))\n",
    "\n",
    "\n",
    "train_mat = None\n",
    "valid_mat = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y_from_ratings(data, N, M):\n",
    "    '''\n",
    "    Create ranking matrix\n",
    "\n",
    "    '''\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)\n",
    "\n",
    "print(\"train_mat shape: \", train_mat.shape)\n",
    "print(\"valid_mat shape: \", valid_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afeb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of non-nan elements in train_mat: \", np.sum(~np.isnan(train_mat))/(943*1682))\n",
    "print(\"Number of non-nan elements in valid_mat: \", np.sum(~np.isnan(valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88827dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b790d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base line model\n",
    "\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Components' : [],\n",
    "          'RMSE': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e7c03-9548-4f8b-813c-302c312cf21d",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Factorization and regularization\n",
    "\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "\n",
    "results = {'Components' : [],\n",
    "          'Mean RMSE': []}\n",
    "\n",
    "for n in range(5 , 30, 5):\n",
    "    model_svd = SVD(n_factors=n, random_state=42)\n",
    "    mean_rmse = round(pd.DataFrame(cross_validate(model_svd, data, measures=['RMSE'], cv=5, verbose=False))['test_rmse'].mean(),3)\n",
    "    results['Components'].append(n)\n",
    "    results['Mean RMSE'].append(mean_rmse)\n",
    "    print(f\"Surprise SVD {n} components Mean RMSE {mean_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(results_df['Components'], results_df['Mean RMSE'])\n",
    "plt.title('Mean RMSE by component parameter', fontsize=18)\n",
    "plt.xlabel('Number of components', fontsize=15)\n",
    "plt.ylabel('Mean RMSE', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ffed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "k = 10\n",
    "algo = SVD(n_factors=k, random_state=42)\n",
    "algo.fit(trainset)\n",
    "svd_preds = algo.test(validset)\n",
    "print(f\"RMSE score for k={k} factors: {accuracy.rmse(svd_preds, verbose=False):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc3ae6-6c91-47cf-a486-9f6ec329359c",
   "metadata": {},
   "source": [
    "### Recommendation Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11917659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code inspired by Nicolas Hug recommedation systems\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def top_n_recs(user_id, n=5):\n",
    "    '''\n",
    "    Function that returns the top n transaction for each user_id \n",
    "    '''\n",
    "    top_n = get_top_n(svd_preds, n=n)\n",
    "    data_temp =pd.DataFrame(top_n[user_id], columns=[\"movie_id\", \"pred\"])\n",
    "    return pd.merge(data_temp, movie_titles, right_on='movie_id', left_on='movie_id', how='left')[['movie_title', 'pred']]\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"\n",
    "    Return the top-N recommendation for each user from a set of predictions of the SVD model\n",
    "\n",
    "    \"\"\"\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 3\n",
    "u_id_sample = ratings[\"user_id\"].sample(size).to_list()\n",
    "u_id_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32861063",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "for user_id in u_id_sample:\n",
    "    print(\"\\nTop %d recommendations for user with id : %d\" % (n, user_id))\n",
    "    df = top_n_recs(user_id, n=n)\n",
    "    df['pred'] = df['pred'].round(decimals = 2)\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-563]",
   "language": "python",
   "name": "conda-env-.conda-563-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
